{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using natural language processing to model the discourse effectiveness of text in the domain of physical exercise instructions.\n",
    "\n",
    "## Phyiscal Exercises:\n",
    "    1.)   Barbell Wrist Curls\n",
    "    2.)   Bench Press\n",
    "    3.)   Crunches\n",
    "    4.)   Deadlift\n",
    "    5.)   Dips\n",
    "    6.)   Dumbbell Curls\n",
    "    7.)   Dumbbell Kickbacks\n",
    "    8.)   Dumbbell Shrugs\n",
    "    9.)   Front Dumbbell Raises\n",
    "    10.)  Front Squats\n",
    "    11.)  Good Mornings\n",
    "    12.)  Hanging Leg Raises\n",
    "    13.)  Hyperextensions\n",
    "    14.)  Incline Bench Press\n",
    "    15.)  Lat Machine Pulldowns\n",
    "    16.)  Leg Curls\n",
    "    17.)  Leg Extensions\n",
    "    18.)  Leg Press\n",
    "    19.)  Lunges\n",
    "    20.)  Lying Triceps Extensions\n",
    "    21.)  Military Press\n",
    "    22.)  Preacher Curls\n",
    "    23.)  Reverse Barbell Curls\n",
    "    24.)  Reverse Crunches\n",
    "    25.)  Seated Triceps Press\n",
    "    26.)  Squats\n",
    "    27.)  Standing Barbell Curls\n",
    "    28.)  Standing Calf Raises\n",
    "    29.)  Straight-Leg Deadlifts\n",
    "    30.)  Triceps Cable Pressdowns\n",
    "    \n",
    "## How is the discourse effectiveness determined?\n",
    "### First, using the researcher's own judgement \"good\" and \"bad\" exercise descriptions were determined. The researcher has an undergraduate minor in Exercise Science and felt comfortable discerning the difference between a good description and a bad one. Please see the references section to see where the descriptions came from.\n",
    "\n",
    "### From there, using the Natural Language Toolkit (NLTK), metrics were used to determine how effective the text was at providing straightforward and safe instructions to perform the physical exercise. Those metrics are: word count, lexical diversity, sentence complexity, sentence similarity, and lexical patterns.\n",
    "\n",
    "### We are hypothesizing the following: \n",
    "###  •  Each good exercise should have a longer description than the associated bad exercise because a good exercise should be more descriptive.\n",
    "###  •  Each good exercise description should have a greater degree of lexical diversity than the associated bad exercise description to create clear imagery of the movement.\n",
    "###  • Each good exercise description should have a lesser degree of complexity per sentence than the associated bad exercise description because less complex sentences are easier to follow.\n",
    "###  •  Each good exercise should description should have sentences that are less similar when compared to the associated bad exercise description. \n",
    "###  •  Each good exercise should be less similar when compared to other good exercises. However, each bad exercise should be more similar when compared to other bad exercises. \n",
    "###  •  Each good exercise should follow a similar lexical pattern of conveying instructions to perform the movement whereas each bad exercise should not have recognizable lexical pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, Function Definitions, and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import textacy\n",
    "from textacy import TextStats\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='mlein50', api_key='q1PZkZjmOXj1zAK2UJNy')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def create_spaces(number_spaces):\n",
    "    count = 0\n",
    "    spaces = \"\"\n",
    "    while count < number_spaces:\n",
    "        spaces += \" \"\n",
    "        count += 1\n",
    "    return spaces\n",
    "\n",
    "\n",
    "def make_word_count_array(file_directory):\n",
    "    word_count_array = []\n",
    "    for individualEx in exercise_list_single_line:\n",
    "        with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/\" + file_directory + \"/\"\n",
    "                  + individualEx + \".txt\", \"r\") as badEx:\n",
    "            text = badEx.read()\n",
    "            words = text.split()\n",
    "            word_count_array.append(len(words))\n",
    "    return word_count_array\n",
    "\n",
    "\n",
    "def lexical_diversity(exercise):\n",
    "    return len(set(exercise)) / len(exercise)\n",
    "\n",
    "\n",
    "def make_lexical_diversity_array(file_directory):\n",
    "    lexical_diversity_array = []\n",
    "    for individEx in exercise_list_single_line:\n",
    "        with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/\" + file_directory +\n",
    "                  \"/\" + individEx + \".txt\", \"r\") as ex:\n",
    "            text = ex.read()\n",
    "            lexical_diversity_array.append(lexical_diversity(text))\n",
    "    return lexical_diversity_array\n",
    "\n",
    "\n",
    "def text_to_doc(file_directory):\n",
    "    doc_array = []\n",
    "    for individualEx in exercise_list_single_line:\n",
    "        with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/\" + file_directory +\n",
    "                  \"/\" + individualEx + \".txt\", \"r\") as exercise:\n",
    "            exerciseText = exercise.read()\n",
    "            docx = textacy.Doc(textacy.preprocess_text(exerciseText, lowercase=True))\n",
    "            doc_array.append(docx)\n",
    "    return doc_array\n",
    "\n",
    "\n",
    "def get_jaccard_sim(str1, str2):\n",
    "    first = set(str1.split())\n",
    "    second = set(str2.split())\n",
    "    intersect = first.intersection(second)\n",
    "    return float(len(intersect)) / (len(first) + len(second) - len(intersect))\n",
    "\n",
    "\n",
    "def make_text_similarity_array(file_directory):\n",
    "    ts_array = []\n",
    "    for i in exercise_list_single_line:\n",
    "        with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/\" + file_directory +\n",
    "                  \"/\" + i + \".txt\", \"r\") as ex1:\n",
    "            text1 = ex1.read()\n",
    "        avg_exercise_similarity = 0\n",
    "        for j in exercise_list_single_line:\n",
    "            with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/\" + file_directory +\n",
    "                      \"/\" + j + \".txt\", \"r\") as ex2:\n",
    "                text2 = ex2.read()\n",
    "                similarity = get_jaccard_sim(text1, text2)\n",
    "                if similarity != 1.0:\n",
    "                    avg_exercise_similarity += similarity\n",
    "        ts_array.append(avg_exercise_similarity/29)\n",
    "    return ts_array\n",
    "\n",
    "\n",
    "exercise_list = open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/exerciseList.txt\", \"r\")\n",
    "exercise_list_single_line = [line.rstrip('\\n') for line in exercise_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count\n",
    "\n",
    "## The word count of each good exercise was determined by the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~mlein50/0 or inside your plot.ly account where it is named 'Good Exercise Word Count Bar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mlein50/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodWordCountAvg = 0\n",
    "goodWordCountArray = []\n",
    "\n",
    "for indivEx in exercise_list_single_line:\n",
    "    with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/GOOD/\" \n",
    "              + indivEx + \".txt\", \"r\") as goodEx:\n",
    "        text = goodEx.read()\n",
    "        words = text.split()\n",
    "        wordTotal = len(words)  #  find word count\n",
    "        goodWordCountArray.append(wordTotal)\n",
    "        goodWordCountAvg += wordTotal\n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=goodWordCountArray,\n",
    "            y=exercise_list_single_line,\n",
    "            marker=dict(\n",
    "                color='rgba(88, 127, 236, 1.0)'),\n",
    "            orientation ='h'\n",
    ")]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Good Exercise Descriptions Word Counts\",\n",
    "    xaxis=dict(\n",
    "        title=\"Number of Words\",\n",
    "        tickfont=dict(\n",
    "            size=12)),    \n",
    "    yaxis=dict(\n",
    "        title=\"Exercise\",\n",
    "        tickprefix=\"\",\n",
    "        showtickprefix=\"all\",\n",
    "        tickfont=dict(\n",
    "            size=10)), \n",
    "    plot_bgcolor='rgb(220, 220, 220)',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Good Exercise Word Count Bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The word count of each bad exercise was determined by the same function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mlein50/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badWordCountAvg = 0\n",
    "badWordCountArray = []\n",
    "\n",
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "\n",
    "for indivEx in exercise_list_single_line:\n",
    "    with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/BAD/\" \n",
    "              + indivEx + \".txt\", \"r\") as badEx:\n",
    "        text = badEx.read()\n",
    "        words = text.split()\n",
    "        wordTotal = len(words)  #  find word count\n",
    "        badWordCountArray.append(wordTotal)\n",
    "        badWordCountAvg += wordTotal\n",
    "\n",
    "\n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=badWordCountArray,\n",
    "            y=exercise_list_single_line,\n",
    "            marker=dict(\n",
    "                color='rgba(222, 95, 95, 1.0)'),\n",
    "            orientation ='h'\n",
    ")]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Bad Exercise Descriptions Word Counts\",\n",
    "    xaxis=dict(\n",
    "        title=\"Number of Words\",\n",
    "        tickfont=dict(\n",
    "            size=12)),    \n",
    "    yaxis=dict(\n",
    "        title=\"Exercise\",\n",
    "        tickprefix=\"\",\n",
    "        showtickprefix=\"all\",\n",
    "        tickfont=dict(\n",
    "            size=10)), \n",
    "    plot_bgcolor='rgb(220, 220, 220)',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Bad Exercise Word Count Bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By doing simple subtraction we can see the difference between the number of words used in good and bad exercise instructions.\n",
    "\n",
    "### NOTE: A negative number represents the good exercise being shorter than the bad exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise\t\t | Word Count Difference\n",
      "------------------------------------------------\n",
      "Barbell Wrist Curls      | 67\n",
      "Bench Press              | 55\n",
      "Crunches                 | 82\n",
      "Deadlift                 | 16\n",
      "Dips                     | 61\n",
      "Dumbbell Curls           | 37\n",
      "Dumbbell Kickbacks       | 37\n",
      "Dumbbell Shrugs          | -2\n",
      "Front Dumbbell Raises    | 71\n",
      "Front Squats             | 1\n",
      "Good Mornings            | 6\n",
      "Hanging Leg Raises       | 30\n",
      "Hyperextensions          | 6\n",
      "Incline Bench Press      | 25\n",
      "Lat Machine Pulldowns    | -29\n",
      "Leg Curls                | 49\n",
      "Leg Extensions           | 45\n",
      "Leg Press                | 20\n",
      "Lunges                   | -13\n",
      "Lying Triceps Extensions | 65\n",
      "Military Press           | 20\n",
      "Preacher Curls           | 63\n",
      "Reverse Barbell Curls    | 53\n",
      "Reverse Crunches         | 88\n",
      "Seated Triceps Press     | 21\n",
      "Squats                   | 10\n",
      "Standing Barbell Curls   | 76\n",
      "Standing Calf Raises     | 100\n",
      "Straight-Leg Deadlifts   | 49\n",
      "Triceps Cable Pressdowns | 40\n"
     ]
    }
   ],
   "source": [
    "#  Difference equation: (Good exercise) - (Bad exercise) = difference in word count\n",
    "wordCountDifferenceArray = []\n",
    "\n",
    "goodExerciseWordCount = list((make_word_count_array(\"GOOD\")))\n",
    "badExerciseWordCount = list((make_word_count_array(\"BAD\")))\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(badExerciseWordCount) and i < len(goodExerciseWordCount):\n",
    "    wordCountDifferenceArray.append((goodExerciseWordCount[i] - badExerciseWordCount[i]))\n",
    "    i += 1\n",
    "\n",
    "if i == len(badExerciseWordCount) and i == len(goodExerciseWordCount):\n",
    "    i = 0\n",
    "    \n",
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "print(\"Exercise\\t\\t |\", \"Word Count Difference\\n\", end=\"\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "for indivEx in exercise_list_single_line:\n",
    "    spaces_to_add = len(exercise_list_single_line[29]) - len(indivEx) #  find word count difference\n",
    "    print(indivEx, end=\"\")\n",
    "    print(create_spaces(spaces_to_add), \"|\", wordCountDifferenceArray[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Category  | Word Count Avg.\n",
      "--------------------------------\n",
      "Good Exercises |     113\n",
      "Bad Exercises  |     75\n"
     ]
    }
   ],
   "source": [
    "print(\"Text Category  | Word Count Avg.\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Good Exercises |    \", round(goodWordCountAvg/30))\n",
    "print(\"Bad Exercises  |    \", round(badWordCountAvg/30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above results indicate only three bad exercise descriptions are longer than their \"good\" counterpart. Those three exercises are: Dumbbell Shrugs, Lat Machine Pulldowns, and Lunges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Diversity\n",
    "\n",
    "## The lexical diversity of each exercise was determined using the function as described in [1].\n",
    "\n",
    "### Good Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise\t\t | Lexical Diversity\n",
      "------------------------------------------------\n",
      "Barbell Wrist Curls      | 0.046008119079837616\n",
      "Bench Press              | 0.052478134110787174\n",
      "Crunches                 | 0.043173862310385065\n",
      "Deadlift                 | 0.059233449477351915\n",
      "Dips                     | 0.05037037037037037\n",
      "Dumbbell Curls           | 0.046130952380952384\n",
      "Dumbbell Kickbacks       | 0.0380952380952381\n",
      "Dumbbell Shrugs          | 0.1\n",
      "Front Dumbbell Raises    | 0.04240766073871409\n",
      "Front Squats             | 0.05154639175257732\n",
      "Good Mornings            | 0.09302325581395349\n",
      "Hanging Leg Raises       | 0.09602649006622517\n",
      "Hyperextensions          | 0.08080808080808081\n",
      "Incline Bench Press      | 0.0658682634730539\n",
      "Lat Machine Pulldowns    | 0.08814589665653495\n",
      "Leg Curls                | 0.05752961082910321\n",
      "Leg Extensions           | 0.05255023183925812\n",
      "Leg Press                | 0.07045454545454545\n",
      "Lunges                   | 0.048154093097913325\n",
      "Lying Triceps Extensions | 0.05066344993968637\n",
      "Military Press           | 0.06490384615384616\n",
      "Preacher Curls           | 0.054775280898876406\n",
      "Reverse Barbell Curls    | 0.05164992826398852\n",
      "Reverse Crunches         | 0.05236907730673317\n",
      "Seated Triceps Press     | 0.06474820143884892\n",
      "Squats                   | 0.061855670103092786\n",
      "Standing Barbell Curls   | 0.04408060453400504\n",
      "Standing Calf Raises     | 0.036231884057971016\n",
      "Straight-Leg Deadlifts   | 0.0465444287729196\n",
      "Triceps Cable Pressdowns | 0.05325443786982249\n"
     ]
    }
   ],
   "source": [
    "goodLexicalDiversityAvg = 0\n",
    "\n",
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "print(\"Exercise\\t\\t |\", \"Lexical Diversity\\n\", end=\"\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "for indivEx in exercise_list_single_line:\n",
    "    with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/GOOD/\" + indivEx + \".txt\", \"r\") as good:\n",
    "        text = good.read()\n",
    "        spaces_to_add = len(exercise_list_single_line[29]) - len(indivEx)\n",
    "        lexical_diversity_value = lexical_diversity(text)\n",
    "        goodLexicalDiversityAvg += lexical_diversity_value\n",
    "        print(indivEx,  end='')\n",
    "        print(create_spaces(spaces_to_add), \"|\", lexical_diversity_value)\n",
    "        \n",
    "        \n",
    "goodLexicalDiversityAvg /= 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise\t\t | Lexical Diversity\n",
      "------------------------------------------------\n",
      "Barbell Wrist Curls      | 0.10497237569060773\n",
      "Bench Press              | 0.08743169398907104\n",
      "Crunches                 | 0.07673267326732673\n",
      "Deadlift                 | 0.06276150627615062\n",
      "Dips                     | 0.08357348703170028\n",
      "Dumbbell Curls           | 0.06622516556291391\n",
      "Dumbbell Kickbacks       | 0.047244094488188976\n",
      "Dumbbell Shrugs          | 0.08333333333333333\n",
      "Front Dumbbell Raises    | 0.07004830917874397\n",
      "Front Squats             | 0.05110497237569061\n",
      "Good Mornings            | 0.09688581314878893\n",
      "Hanging Leg Raises       | 0.23275862068965517\n",
      "Hyperextensions          | 0.0855457227138643\n",
      "Incline Bench Press      | 0.08533333333333333\n",
      "Lat Machine Pulldowns    | 0.06286836935166994\n",
      "Leg Curls                | 0.08641975308641975\n",
      "Leg Extensions           | 0.07192575406032482\n",
      "Leg Press                | 0.1\n",
      "Lunges                   | 0.04978038067349927\n",
      "Lying Triceps Extensions | 0.0625\n",
      "Military Press           | 0.09473684210526316\n",
      "Preacher Curls           | 0.07792207792207792\n",
      "Reverse Barbell Curls    | 0.06981981981981981\n",
      "Reverse Crunches         | 0.0851063829787234\n",
      "Seated Triceps Press     | 0.07075471698113207\n",
      "Squats                   | 0.06573705179282868\n",
      "Standing Barbell Curls   | 0.07654320987654321\n",
      "Standing Calf Raises     | 0.06765327695560254\n",
      "Straight-Leg Deadlifts   | 0.06584362139917696\n",
      "Triceps Cable Pressdowns | 0.0668103448275862\n"
     ]
    }
   ],
   "source": [
    "badLexicalDiversityAvg = 0\n",
    "\n",
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "print(\"Exercise\\t\\t |\", \"Lexical Diversity\\n\", end=\"\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "for indivEx in exercise_list_single_line:\n",
    "    with open(\"/Users/matthewleinhauser/Documents/NLP Research Project/Exercises/BAD/\" + indivEx + \".txt\", \"r\") as bad:\n",
    "        text = bad.read()\n",
    "        spaces_to_add = len(exercise_list_single_line[29]) - len(indivEx)\n",
    "        lexical_diversity_value = lexical_diversity(text)\n",
    "        badLexicalDiversityAvg += lexical_diversity_value\n",
    "        print(indivEx,  end='')\n",
    "        print(create_spaces(spaces_to_add), \"|\", lexical_diversity_value)\n",
    "        \n",
    "        \n",
    "badLexicalDiversityAvg /= 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By doing simple subtraction we can see the difference between the lexical diversity used in good and bad exercise instructions.\n",
    "\n",
    "### NOTE: A negative number represents the good exercise being less lexically diverse than the bad exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise\t\t | Lexical Diversity Difference\n",
      "------------------------------------------------\n",
      "Barbell Wrist Curls      | -0.058964256610770115\n",
      "Bench Press              | -0.034953559878283864\n",
      "Crunches                 | -0.033558810956941666\n",
      "Deadlift                 | -0.0035280567987987094\n",
      "Dips                     | -0.03320311666132991\n",
      "Dumbbell Curls           | -0.02009421318196153\n",
      "Dumbbell Kickbacks       | -0.009148856392950877\n",
      "Dumbbell Shrugs          | 0.016666666666666677\n",
      "Front Dumbbell Raises    | -0.027640648440029877\n",
      "Front Squats             | 0.0004414193768867078\n",
      "Good Mornings            | -0.0038625573348354397\n",
      "Hanging Leg Raises       | -0.13673213062342998\n",
      "Hyperextensions          | -0.004737641905783491\n",
      "Incline Bench Press      | -0.019465069860279433\n",
      "Lat Machine Pulldowns    | 0.025277527304865016\n",
      "Leg Curls                | -0.028890142257316537\n",
      "Leg Extensions           | -0.019375522221066706\n",
      "Leg Press                | -0.029545454545454555\n",
      "Lunges                   | -0.001626287575585944\n",
      "Lying Triceps Extensions | -0.01183655006031363\n",
      "Military Press           | -0.029832995951417002\n",
      "Preacher Curls           | -0.023146797023201514\n",
      "Reverse Barbell Curls    | -0.01816989155583129\n",
      "Reverse Crunches         | -0.032737305671990236\n",
      "Seated Triceps Press     | -0.006006515542283153\n",
      "Squats                   | -0.0038813816897358966\n",
      "Standing Barbell Curls   | -0.03246260534253818\n",
      "Standing Calf Raises     | -0.031421392897631524\n",
      "Straight-Leg Deadlifts   | -0.019299192626257358\n",
      "Triceps Cable Pressdowns | -0.013555906957763715\n"
     ]
    }
   ],
   "source": [
    "lexicalDiversityDifferenceArray = []\n",
    "\n",
    "goodExerciseLexicalDiversity = list((make_lexical_diversity_array(\"GOOD\")))\n",
    "badExerciseLexicalDiversity = list((make_lexical_diversity_array(\"BAD\")))\n",
    "\n",
    "i = 0\n",
    "while i < len(badExerciseLexicalDiversity) and i < len(goodExerciseLexicalDiversity):\n",
    "    lexicalDiversityDifferenceArray.append((goodExerciseLexicalDiversity[i] - badExerciseLexicalDiversity[i]))\n",
    "    i += 1\n",
    "\n",
    "if i == len(badExerciseLexicalDiversity) and i == len(goodExerciseLexicalDiversity):\n",
    "    i = 0\n",
    "    \n",
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "print(\"Exercise\\t\\t |\", \"Lexical Diversity Difference\\n\", end=\"\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "for indivEx in exercise_list_single_line:\n",
    "    spaces_to_add = len(exercise_list_single_line[29]) - len(indivEx)\n",
    "    print(indivEx, end=\"\")\n",
    "    print(create_spaces(spaces_to_add), \"|\", lexicalDiversityDifferenceArray[i])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Lexical Diversity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Category  | Lexical Diversity Score Avg.\n",
      "---------------------------------------------\n",
      "Good Exercises |\t 5.877\n",
      "Bad Exercises  |\t 8.028\n"
     ]
    }
   ],
   "source": [
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "print(\"Text Category  | Lexical Diversity Score Avg.\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Good Exercises |\\t\", round(goodLexicalDiversityAvg * 100, 3))\n",
    "print(\"Bad Exercises  |\\t\", round(badLexicalDiversityAvg * 100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above results indicate only three bad exercise descriptions are longer than their \"good\" counterpart. Those three exercises are: Dumbbell Shrugs, Front Squats, and Lat Machine Pulldowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To measure text complexity, the researcher used four readability metrics as defined in [11] and the functions used are found in the API of [10]. Those metrics are: Flesch-Kincaid Reading Ease, Flesch-Kincaid Grade Level, Gunning-Fog Score, and Automated Readability Index\n",
    "\n",
    "### NOTE: These readability metrics were rounded to the nearest integer\n",
    "\n",
    "### Good Exercise Readability Metric Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise\t\t | Reading Ease | Grade Level | Gunning-Fog Score | Automated Readability Index\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Barbell Wrist Curls      |\t 81     |       7     |\t      10 \t  |\t     9\n",
      "Bench Press              |\t 81     |       6     |\t      8  \t  |\t     7\n",
      "Crunches                 |\t 80     |       6     |\t      9  \t  |\t     8\n",
      "Deadlift                 |\t 85     |       5     |\t      8  \t  |\t     6\n",
      "Dips                     |\t 65     |       12    |\t      14 \t  |\t     12\n",
      "Dumbbell Curls           |\t 67     |       10    |\t      12 \t  |\t     12\n",
      "Dumbbell Kickbacks       |\t 76     |       7     |\t      9  \t  |\t     9\n",
      "Dumbbell Shrugs          |\t 90     |       4     |\t      6  \t  |\t     4\n",
      "Front Dumbbell Raises    |\t 74     |       10    |\t      12 \t  |\t     12\n",
      "Front Squats             |\t 86     |       5     |\t      8  \t  |\t     5\n",
      "Good Mornings            |\t 82     |       6     |\t      9  \t  |\t     8\n",
      "Hanging Leg Raises       |\t 76     |       7     |\t      10 \t  |\t     9\n",
      "Hyperextensions          |\t 69     |       8     |\t      10 \t  |\t     10\n",
      "Incline Bench Press      |\t 86     |       5     |\t      8  \t  |\t     6\n",
      "Lat Machine Pulldowns    |\t 81     |       7     |\t      8  \t  |\t     8\n",
      "Leg Curls                |\t 78     |       6     |\t      9  \t  |\t     7\n",
      "Leg Extensions           |\t 72     |       9     |\t      12 \t  |\t     11\n",
      "Leg Press                |\t 74     |       8     |\t      10 \t  |\t     10\n",
      "Lunges                   |\t 74     |       8     |\t      11 \t  |\t     11\n",
      "Lying Triceps Extensions |\t 80     |       8     |\t      10 \t  |\t     10\n",
      "Military Press           |\t 62     |       10    |\t      12 \t  |\t     12\n",
      "Preacher Curls           |\t 78     |       7     |\t      10 \t  |\t     8\n",
      "Reverse Barbell Curls    |\t 87     |       5     |\t      8  \t  |\t     6\n",
      "Reverse Crunches         |\t 84     |       6     |\t      8  \t  |\t     6\n",
      "Seated Triceps Press     |\t 79     |       6     |\t      9  \t  |\t     7\n",
      "Squats                   |\t 82     |       8     |\t      10 \t  |\t     9\n",
      "Standing Barbell Curls   |\t 81     |       7     |\t      10 \t  |\t     8\n",
      "Standing Calf Raises     |\t 75     |       8     |\t      11 \t  |\t     10\n",
      "Straight-Leg Deadlifts   |\t 74     |       10    |\t      13 \t  |\t     12\n",
      "Triceps Cable Pressdowns |\t 79     |       8     |\t      10 \t  |\t     9\n"
     ]
    }
   ],
   "source": [
    "good_reading_ease_avg = 0\n",
    "good_grade_level_avg = 0\n",
    "good_gunning_fog_avg = 0\n",
    "good_ari_avg = 0\n",
    "\n",
    "goodExerciseDocArray = list((text_to_doc(\"GOOD\")))\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(goodExerciseDocArray):\n",
    "    ts1 = TextStats(goodExerciseDocArray[i])\n",
    "    goodExerciseDocArray[i] = list((round(ts1.flesch_reading_ease),\n",
    "                                    round(ts1.flesch_kincaid_grade_level),\n",
    "                                    round(ts1.gunning_fog_index),\n",
    "                                    round(ts1.automated_readability_index)))\n",
    "    if goodExerciseDocArray[i][1] > 12:\n",
    "        goodExerciseDocArray[i][1] = 12\n",
    "    if goodExerciseDocArray[i][3] > 12:\n",
    "        goodExerciseDocArray[i][3] = 12\n",
    "    good_reading_ease_avg += goodExerciseDocArray[i][0]\n",
    "    good_grade_level_avg += goodExerciseDocArray[i][1]\n",
    "    good_gunning_fog_avg += goodExerciseDocArray[i][2]\n",
    "    good_ari_avg += goodExerciseDocArray[i][3]\n",
    "    i += 1\n",
    "\n",
    "if i == len(goodExerciseDocArray):\n",
    "    good_reading_ease_avg /= 30\n",
    "    good_grade_level_avg /= 30\n",
    "    good_gunning_fog_avg /= 30\n",
    "    good_ari_avg /= 30\n",
    "    i = 0\n",
    "\n",
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "print(\"Exercise\\t\\t | Reading Ease | Grade Level | Gunning-Fog Score | Automated Readability Index\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "for individualEx in exercise_list_single_line:\n",
    "    character_dif = len(exercise_list_single_line[29]) - len(individualEx)\n",
    "    print(individualEx, end='')\n",
    "    print(create_spaces(character_dif), \"|\\t\", goodExerciseDocArray[i][0], end='')\n",
    "    character_dif = len(str(goodExerciseDocArray[4][0])) - len(str(goodExerciseDocArray[i][0]))\n",
    "    print(create_spaces(character_dif), \"    |      \", goodExerciseDocArray[i][1], end='')\n",
    "    character_dif = len(str(goodExerciseDocArray[4][1])) - len(str(goodExerciseDocArray[i][1]))\n",
    "    print(create_spaces(character_dif), \"   |\\t     \", goodExerciseDocArray[i][2], end='')\n",
    "    character_dif = len(str(goodExerciseDocArray[4][2])) - len(str(goodExerciseDocArray[i][2]))\n",
    "    print(create_spaces(character_dif), \"\\t  |\\t    \", goodExerciseDocArray[i][3])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad Exercise Readability Metric Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise\t\t | Reading Ease | Grade Level | Gunning-Fog Score | Automated Readability Index\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Barbell Wrist Curls      |\t 84     |       6     |\t      9 \t  |\t     7\n",
      "Bench Press              |\t 91     |       3     |\t      7 \t  |\t     4\n",
      "Crunches                 |\t 82     |       6     |\t      9 \t  |\t     6\n",
      "Deadlift                 |\t 80     |       6     |\t      9 \t  |\t     8\n",
      "Dips                     |\t 71     |       8     |\t      12 \t  |\t     10\n",
      "Dumbbell Curls           |\t 78     |       8     |\t      10 \t  |\t     10\n",
      "Dumbbell Kickbacks       |\t 73     |       8     |\t      10 \t  |\t     9\n",
      "Dumbbell Shrugs          |\t 72     |       7     |\t      8 \t  |\t     9\n",
      "Front Dumbbell Raises    |\t 70     |       10    |\t      12 \t  |\t     12\n",
      "Front Squats             |\t 75     |       6     |\t      8 \t  |\t     6\n",
      "Good Mornings            |\t 77     |       5     |\t      6 \t  |\t     6\n",
      "Hanging Leg Raises       |\t 69     |       9     |\t      13 \t  |\t     9\n",
      "Hyperextensions          |\t 79     |       6     |\t      8 \t  |\t     8\n",
      "Incline Bench Press      |\t 90     |       4     |\t      7 \t  |\t     4\n",
      "Lat Machine Pulldowns    |\t 79     |       7     |\t      10 \t  |\t     9\n",
      "Leg Curls                |\t 78     |       7     |\t      11 \t  |\t     10\n",
      "Leg Extensions           |\t 78     |       6     |\t      11 \t  |\t     8\n",
      "Leg Press                |\t 82     |       5     |\t      7 \t  |\t     6\n",
      "Lunges                   |\t 82     |       6     |\t      9 \t  |\t     8\n",
      "Lying Triceps Extensions |\t 78     |       7     |\t      9 \t  |\t     8\n",
      "Military Press           |\t 79     |       5     |\t      7 \t  |\t     6\n",
      "Preacher Curls           |\t 74     |       7     |\t      10 \t  |\t     9\n",
      "Reverse Barbell Curls    |\t 83     |       6     |\t      7 \t  |\t     8\n",
      "Reverse Crunches         |\t 86     |       5     |\t      8 \t  |\t     6\n",
      "Seated Triceps Press     |\t 82     |       7     |\t      9 \t  |\t     9\n",
      "Squats                   |\t 76     |       7     |\t      8 \t  |\t     9\n",
      "Standing Barbell Curls   |\t 82     |       5     |\t      7 \t  |\t     7\n",
      "Standing Calf Raises     |\t 75     |       7     |\t      11 \t  |\t     9\n",
      "Straight-Leg Deadlifts   |\t 70     |       8     |\t      10 \t  |\t     9\n",
      "Triceps Cable Pressdowns |\t 83     |       6     |\t      9 \t  |\t     7\n"
     ]
    }
   ],
   "source": [
    "bad_reading_ease_avg = 0\n",
    "bad_grade_level_avg = 0\n",
    "bad_gunning_fog_avg = 0\n",
    "bad_ari_avg = 0\n",
    "\n",
    "badExerciseDocArray = list((text_to_doc(\"BAD\")))\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(badExerciseDocArray):\n",
    "    ts2 = TextStats(badExerciseDocArray[i])\n",
    "    badExerciseDocArray[i] = list((round(ts2.flesch_reading_ease),\n",
    "                                   round(ts2.flesch_kincaid_grade_level),\n",
    "                                   round(ts2.gunning_fog_index),\n",
    "                                   round(ts2.automated_readability_index)))\n",
    "    if badExerciseDocArray[i][1] > 12:\n",
    "        badExerciseDocArray[i][1] = 12\n",
    "    if badExerciseDocArray[i][3] > 12:\n",
    "        badExerciseDocArray[i][3] = 12\n",
    "    bad_reading_ease_avg += badExerciseDocArray[i][0]\n",
    "    bad_grade_level_avg += badExerciseDocArray[i][1]\n",
    "    bad_gunning_fog_avg += badExerciseDocArray[i][2]\n",
    "    bad_ari_avg += badExerciseDocArray[i][3]\n",
    "    i += 1\n",
    "\n",
    "if i == len(badExerciseDocArray):\n",
    "    bad_reading_ease_avg /= 30\n",
    "    bad_grade_level_avg /= 30\n",
    "    bad_gunning_fog_avg /= 30\n",
    "    bad_ari_avg /= 30\n",
    "    i = 0\n",
    "\n",
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "print(\"Exercise\\t\\t | Reading Ease | Grade Level | Gunning-Fog Score | Automated Readability Index\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "for individualEx in exercise_list_single_line:\n",
    "    character_dif = len(exercise_list_single_line[29]) - len(individualEx)\n",
    "    print(individualEx, end='')\n",
    "    print(create_spaces(character_dif), \"|\\t\", badExerciseDocArray[i][0], end='')\n",
    "    character_dif = len(str(badExerciseDocArray[8][0])) - len(str(badExerciseDocArray[i][0]))\n",
    "    print(create_spaces(character_dif), \"    |      \", badExerciseDocArray[i][1], end='')\n",
    "    character_dif = len(str(badExerciseDocArray[8][1])) - len(str(badExerciseDocArray[i][1]))\n",
    "    print(create_spaces(character_dif), \"   |\\t     \", badExerciseDocArray[i][2], end='')\n",
    "    character_dif = len(str(badExerciseDocArray[8][2])) - len(str(badExerciseDocArray[8][2]))\n",
    "    print(create_spaces(character_dif), \"\\t  |\\t    \", badExerciseDocArray[i][3])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readability Metrics Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Category  | Reading Ease Avg. | Grade Level Avg. | Gunning-Fog Score Avg. | Automated Readability Index Avg.\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Good Exercises |       77.933 \t   |\t    7         |\t\t 10 \t       |\t 9\n",
      "Bad Exercises  |       78.6 \t   |\t    6         |\t\t 9 \t       |\t 8\n"
     ]
    }
   ],
   "source": [
    "good_reading_ease_avg = round(good_reading_ease_avg, 3)\n",
    "good_grade_level_avg = round(good_grade_level_avg)\n",
    "good_gunning_fog_avg = round(good_gunning_fog_avg)\n",
    "good_ari_avg = round(good_ari_avg)\n",
    "bad_reading_ease_avg = round(bad_reading_ease_avg, 3)\n",
    "bad_grade_level_avg = round(bad_grade_level_avg)\n",
    "bad_gunning_fog_avg = round(bad_gunning_fog_avg)\n",
    "bad_ari_avg = round(bad_ari_avg)\n",
    "\n",
    "#  The following lines are only for printing format on the Jupyter Notebook and in no way are a reflection of\n",
    "#  good coding standards and practices.\n",
    "\n",
    "print(\"Text Category  | Reading Ease Avg. | Grade Level Avg. | Gunning-Fog Score Avg. | \"\n",
    "      \"Automated Readability Index Avg.\")\n",
    "print(\"-----------------------------------------------------------------------------------------------------\"\n",
    "      \"------------\")\n",
    "print(\"Good Exercises |      \", good_reading_ease_avg, \"\\t   |\\t   \", good_grade_level_avg, \"        |\\t\\t\",\n",
    "      good_gunning_fog_avg, \"\\t       |\\t\", good_ari_avg)\n",
    "print(\"Bad Exercises  |      \", bad_reading_ease_avg, \"\\t   |\\t   \", bad_grade_level_avg, \"        |\\t\\t\",\n",
    "      bad_gunning_fog_avg, \"\\t       |\\t\", bad_ari_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To measure text similarity, the researcher used a few different metrics. The first metric used is Jaccard Similarity as defined as a term and python function in [12]. The results shown for each exercise under the sub-headings \"Good Exercise Text Similarity Metric Scores\" and \"Bad Exercise Text Similarity Metric Scores\" are an average of the text similarity of each exercise compared to the other 29 exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Exercise Text Similarity Metric Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_similarity_array = []\n",
    "\n",
    "good_exercise_similarity_array = list((make_text_similarity_array(\"GOOD\")))\n",
    "bad_exercise_similarity_array = list((make_text_similarity_array(\"BAD\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad Exercise Text Similarity Metric Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Similarity Metrics Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15425529993832607\n",
      "0.17716052153679454\n"
     ]
    }
   ],
   "source": [
    "good_similarity_total = 0\n",
    "bad_similarity_total = 0\n",
    "k = 0\n",
    "\n",
    "while k < len(exercise_list_single_line):\n",
    "    good_similarity_total += float(good_exercise_similarity_array[k])\n",
    "    bad_similarity_total += float(bad_exercise_similarity_array[k])\n",
    "    k += 1\n",
    "    \n",
    "good_similarity_avg = good_similarity_total/len(exercise_list_single_line)\n",
    "bad_similarity_avg = bad_similarity_total/len(exercise_list_single_line)\n",
    "\n",
    "print(good_similarity_avg)\n",
    "print(bad_similarity_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "## Books Used:\n",
    "### [1] Bird, S., Klein, E., & Loper, E. (2009). Natural Language Processing with Python. Beijing: OReilly Media.\n",
    "### [2] Schwarzenegger, A., & Dobbins, B. (2012). The New Encyclopedia of Modern Bodybuilding:. Simon & Schuster USA.\n",
    "### [3] Price, R. G. (2014). Ultimate Guide to Weight Training for Running. Chicago, IL: Price World Publishing.\n",
    "### [4] Price, R. G. (2004). The Ultimate Guide to Weight Training for Baseball and Softball. Cleveland, OH: Price World Enterprises.\n",
    "### [5] Price, R. G. (2006). Ultimate Guide to Weight Training for Golf. Cleveland, OH: Price World Enterprises.\n",
    "### [6] Little, J. R. (2008). Beginning Bodybuilding: Real Muscle/Real Fast. New York, NY: McGraw-Hill.\n",
    "### [7] Zyzz's Bodybuilding Bible. (2011).\n",
    "### [8] Brungardt, K. (1999). The Complete Book of Abs. New York, NY: Random House.\n",
    "### [9] Explosion AI. (2016). Architecture · spaCy API Documentation. Retrieved from https://spacy.io/api/\n",
    "### [10] Chartbeat, Inc. (2016). API Reference. Retrieved from https://chartbeat-labs.github.io/textacy/api_reference.html\n",
    "### [11] Conzett, L. (2017, October 10). What are Readability Metrics? Retrieved from https://raven.zendesk.com/hc/en-us/articles/202308564-What-are-Readability-Metrics-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
